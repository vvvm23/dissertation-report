% TODO: still listing what I did, no bueno.
% TODO: end is all negative
% first is fine, so is second. indeed is bad though
% highlight a trend in the literature that we follow
% TODO: some kind of surprise
% TODO: what have I learned from the project?
% TODO: anything that contradicts? Surprises? Summarise anything citeable.

In conclusion, we investigated pushing the efficiency of generative models via
the combination of various techniques, following the general trend in generative
modelling of simultaneously improving quality and speed of sampling using
non-adversarial approaches. We found that the combination of these techniques
did indeed result in a fast generative model that was scaled to very high
resolutions, demonstrating the usefulness of denoising autoencoders as
generative models of discrete latents. We also improved the architecture of
hierarchical transformers to make them more suited for multi-dimensional data.
Despite our framework supporting very fast sampling, there is much room for
further work. For one, better \gls{vq} image models that do not rely on
adversarial components, to avoid patch-wise mode collapse. Secondly, a more
through parameter search to improve the sample quality further as measured by
perceptual quality metrics, especially in ImageNet experiments. Finally, an
investigation into conditioning the generator model on text prompts, allowing
for very fast text-to-image generation.
