In this work we investigated pushing the efficiency of generative models via the
combination of various techniques, following the general trend in generative
modelling of simultaneously improving quality and speed of sampling using
non-adversarial approaches. We found that the combination of these techniques
formed a fast image generation framework. To our surprise, the proposed method
was faster and more scaleable than expected, able to be applied with ease to
megapixel images, and generate samples at such resolutions in seconds -- a wide
margin faster than prior non-adversarial methods. Additionally, we found that
previously proposed hourglass transformers are not optimally defined on
multi-dimensional inputs and subsequently proposed adjustments to them. We also
demonstrated the scalability of \gls{sundae} by applying it to sequences of
length 1024 -- eight times longer than evaluated on in the original work. Our work
demonstrates the superiority of the \acrlong{nar} paradigm, and joins a rapidly
growing space of research into their use as a viable alternative to \acrlong{ar}
frameworks. Additional research is needed into better \gls{vq} image models and
into a stronger conditional generative model.
